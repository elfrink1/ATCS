#!/bin/bash
#SBATCH -p gpu_titanrtx_shared_course
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --job-name=hp1.0e-3
#SBATCH --cpus-per-task=3
#SBATCH --time=08:00:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module load 2019
module load Python
module load NCCL/2.5.6-CUDA-10.1.243

# Your job starts in the directory where you call sbatch
cd $HOME/atcs2

# Activate your environment
source activate atcs2

python train_bert.py hp0.0001 hp 41 --lr 0.0001 --max_text_length 512 --batch_size 32 --finetuned_layers -1 