Initial setup: 
We have a base model M_init (e.g. BERT + small MLP) with parameters Î¸
For each episode:

Step 1 Sample a support set S and query set Q for the task

Step 2 Duplicate the base model with deepcopy, the higher library or
by copying the parameters Î¸ to a new instance. The new model is
referred to as Mepisode with parameters Î¸(0). Make sure the gradients
are zero in the model.

Step 3 Apply your original base model, M_init, on the support set S and
calculate the prototype-based parameters of the linear layer, Î³. Do
not apply torch.no grad() or similar here. We will need gradients
through the init part.

Step 4 Initialize the output layer parameters Ï†(0) with the previously 
calculated prototype initialization Î³. Thereby, detach the initialization 
so that the computation graph for calculating the prototypes is independent of the inner loop updates

Step 5 Take k inner loop steps on the support set S with your episode model, Mepisode, 
including the output parameters. Your final parameters are Î¸(k) and Ï†(k)

Step 6 Replace Ï†(k) with Ï†(k) = Î³ + detach(Ï†(k) âˆ’ Î³)


This trick adds the original prototypes back to the computation graph
without changing the output parameter values. Note that you have
to do this for both weight and bias parameter. In particular, for the
weight parameter, your code could look something like this:
W = 2 * prototypes + (W - 2 * prototypes).detach()

Step 7 Apply the trained episode model Mepisode on the query set Q, and
calculate the gradients with respect to Î¸(k) and Î¸ using torch.autograd.grad.

Step 8 Sum the gradients for Î¸(k) and Î¸, and store them in the gradient
placeholder of your original model M_init. In case this is not the first
episode, sum the new gradients with the ones already stored in M_init.
Outer loop update Perform one update step using the gradients stored in
M_init. Afterwards, set them to zero.

Outer loop update 
Perform one update step using the gradients stored in M_init. 
Afterwards, set them to zero.



The implementation is designed to be fast. In case you run out of memory,
you can change the code as follows to make it more memory ecient for the
cost of speed:

- Calculate the prototype initialization without gradients (apply torch.no grad.

- After finishing the k inner loop steps, first calculate the gradients of Q
with respect to Î¸(k), without step 6. The gradients can be directly added
to the Minit model. For eciency, store the output of the episode model,
M_episode, just before the output layer (remember to detach it).

- Calculate the prototype initialization with Mbase again, but this time with
gradients. Afterwards, perform step 6.

- Forward the stored output of Mepisode through the output layer, and calculate 
the gradients now with respect to . Add the gradients as well to M_init.

In this setup, you only have a single computation graph at once in the memory.
However, one additional forward pass is needed for this approach.